
- how to organize thing such that it's actually easy to compose this with
  arbitrary scripts to specify trials structures? i'm feeling like i might not
  want to try to anticipate all ways of representing trials in here... not sure.
  - maybe accept a python file in place of yaml, which must follow a certain
    format (function / variable with a certain name? some less hacky way?)
    that outputs either YAML or the pre-serialization equivalent
    - would i want to support certain types of inputs to these sorts of
      functions?

- write scripts that can be used with another arduino / DAQ board to verify that
  parts of this are working, such as:
  - arduino script that detects which pins are high (connect pins 1:1) and
    reports
  - script that interprets DAQ signals to measure timing and check
  
- add something to do all install steps on clone?
  + do i need to also clone that submodule? probably, right?

- arduino emulation for on-host integration tests?

- add windows steps to install instructions. and are they the same as would
  be needed on a fresh 18.04 anyway? (seems we start in dialout in WSL, so
  steps aren't exactly the same...)
  - git submodule update --init (in this repo top-level)
  - sudo apt install python3-pip
  - sudo apt install python3-venv
  - sudo apt install protobuf-compiler
  - (after making and activating virtualenv) pip install --upgrade pip
    (or else some of stuff in requirements.txt doesn't build)

- in 16.04, after installing python3.6 from deadsnakes repo, also needed to
  install python3.6-venv to not have the ensurepip error (pip was already
  installed)

  - need to download protobuf source from here:
    https://github.com/protocolbuffers/protobuf/archive/v3.0.0.tar.gz

    ... and compile, to have same version as installed with apt on 18.04

    See: https://askubuntu.com/questions/1072683

    Needed to modify above askubuntu instructions by following jalajc's comment
    here: https://github.com/samjabrahams/tensorflow-on-raspberry-pi/issues/42
    (I just manually ran them inside protobuf source root)

    Then I needed to do ./autogen.sh before ./configure existed.

    TODO TODO TODO fix errors / warnings that caused: make check
    to fail in protobuf 3.0.0 build!

    TODO also run nanopb tests and see if those work!

    The version that apt installs in 16.04 doesn't support version 3 of the
    protocol (the version I use).

- implement some stuff to assist manual testing
  - pulse valve at a configurable duty cycle / on off pulse widths until
    manually advanced? or switch between them (all avail pins) at some
    configurable rate?

  - if getting input from flow meters, and the valves can be switched so that no
    flow is allowed through one of the flow meters, could probably read the flow
    as a test and switch valves individually to check they allow flow

    - this + knowing pins are all driving different valves seems like a pretty
      good guarantee everything is wired correctly + the valves are working

- !!! add ability to restart from wherever, in case something went wrong!

- compare message / code size (if even available) / deserialization time of:
  - protobuf (using nanopb, probably)
  - msgpack
  - flatbuffers
  - capnproto
  - the json library will uses
  - ROS? (only if it seems clear how to just use their serialization /
    deserialization stuff, without commiting too much else to the ecosystem,
    particularly on the uC code size front...)
  - python struct? maybe defeats the purpose...
  - are there any libraries that support small types like python struct can?

- run arduino code through valgrid (and setup olf-upload flags for that) and any
  other useful detectors of potential code problems

- in pulse_timing case (or if i modify follow_hardware_timing==True case to have
  a time estimate for each, or if i estimate during experiment) print time
  experiment will take (or estimate of it)
  - + in follow_* case, just time how long it took
  - + in both cases, also report how long after it finished ctrl c was pressed
  - (at this point maybe just actually exit in python though, rather than
    prompting user to press ctrl-C? both require parsing finished basically...)

- !!!!! have python send an abort command atexit (or if i implement olfactometer
  as context manager, in cleanup portion of that). i want to be able to ctrl-C
  stuff without having it continue delivering odors!

- !!!! ensure that hardware pulses beyond end don't trigger anything until
  python actual initaites again (in follow_* case). i feel like i saw one case
  2020-08-17 where that was not the case.

- print something clarify whether "trial: ..." status prints come at the
  beginning / end of trial or where. change if necessary depending on whether
  follow_* is true

- !!!! timeout on / after "Connected" step, to get timely err if uC code isn't
  uploaded (also maybe color Connected orange and / or at least Ready green?)
  (or automatically upload if timeout passes? to not forget -u?)

- make some canonical path (env var modifiable) for files describing
  configuration of each olfactometer (~each rig, if 1:1), assuming hardware is
  allowed to vary (which, let's be real, it will)
